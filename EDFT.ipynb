{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHEsUwSBCHbK"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRPrD_ccFVz9"
      },
      "source": [
        "The project aims to create a **Machine Learning** powered model which is capable of classifying the emotions of the text (in the form of short quotes/comments) with predefined labels of emotions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMh_xASYG7cZ"
      },
      "source": [
        "Emotion detection, also known as sentiment analysis, is now one of the most attractive subfields of Machine Learning, especially Natural Language Processing (NLP) due to its wide applications in many aspects of modern life, such as providing emotional information to help people developing insights or making decisions. In this project, we specifically try to convey the main emotion of a comment sentence. Generally, we expect the model to be able to take the input sentence in the form of short comments and returns its major emotion(s), corresponding to one of the predefined labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T65Wg0STHA3s"
      },
      "source": [
        "Our approach to solving this problem is to split it into two halves:\n",
        "\n",
        "  1.   Data Preprocessing\n",
        "  2.   Model training and Result\n",
        "\n",
        "For detail of each half, please go into the section\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDK4XIuNIgMl"
      },
      "source": [
        "The dataset we use in this project is obtained from Kaggle: [EDFT Dataset](https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CJSmsQlUZJt"
      },
      "source": [
        "Connect to Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj7DW4_mFDBh"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDTriPXukNqb"
      },
      "source": [
        "## Importation & Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKqQ0TvIZSOK"
      },
      "source": [
        "Preparing necessary packages (may need to add more):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TbRS-hBXsHe"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # Work with multi-dimenional data\n",
        "import pandas as pd # Work with relational data\n",
        "import matplotlib.pyplot as plt # Visualize data\n",
        "import seaborn as sns # Visualize data base on matplotlib\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Because I hate seeing stupid warnings~\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "# Used for automatic feature extraction\n",
        "from sklearn.pipeline import Pipeline\n",
        "# Used for automating processes\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, cross_val_score\n",
        "# Used for spliting test and tuning hyperparameter\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "# Used for k-fold validiator in multi-classficiation\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Defining kNN\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# Defining Decision Tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Defining Random Forest\n",
        "from sklearn.svm import SVC\n",
        "# Defining Classifier SVM\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "# Defining Naive Bayes\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "# Used for calculating metric-related scores of the model performance, and plotting the confusion matrix\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTgWau1hdl23"
      },
      "source": [
        "Load data from files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY138Gindon3",
        "outputId": "20e0b050-60cd-4a03-ffc8-2a8cd393aa5b"
      },
      "outputs": [],
      "source": [
        "directory = 'data/dataset/'\n",
        "\n",
        "# This method use to extract all the file in the input list\n",
        "def extract_data(files):\n",
        "  data_x_raw = list()\n",
        "  data_y_raw = list()\n",
        "  for file in files:\n",
        "    with open(directory + file) as f:\n",
        "      for line in f:\n",
        "        line = line.strip('\\n')\n",
        "        x_raw, y_raw = line.split(sep=';')\n",
        "\n",
        "        data_x_raw.append(x_raw)\n",
        "        data_y_raw.append(y_raw)\n",
        "\n",
        "  return data_x_raw, data_y_raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get all data\n",
        "\n",
        "X_raw, y_raw = extract_data(['train.txt', 'val.txt', 'test.txt'])\n",
        "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_raw, y_raw, test_size = 0.2)\n",
        "\n",
        "print(\"Traning data's size is:\", len(X_train_raw))\n",
        "print(\"Test data's size is:\", len(X_test_raw))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UhsCl8HgxKV"
      },
      "source": [
        "## Inital feature Extraction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkacoVpjhG6O"
      },
      "source": [
        "Removing the stopword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OCse4nNgaoy"
      },
      "outputs": [],
      "source": [
        "file = open(\"data/stopwords/stop_words_english.txt\", 'r')\n",
        "stopword_list = file.read().split('\\n')\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRGC3YwhD6Qx"
      },
      "source": [
        "Vectorize the data:\n",
        "\n",
        "1.   Bag Of Words model (https://en.wikipedia.org/wiki/Bag-of-words_model)\n",
        "2.   BoW/TF-IDF model (https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY6UaDwAD_Aj",
        "outputId": "1a4102e0-7a25-4fcd-8804-cd327552d601"
      },
      "outputs": [],
      "source": [
        "# Scikit CountVectorizer:\n",
        "# Documentation: (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
        "\n",
        "count_vector = CountVectorizer(stop_words=stopword_list, ngram_range=(1, 2))\n",
        "count_vector.fit(X_train_raw, X_test_raw)\n",
        "X_train_bow = count_vector.transform(X_train_raw)\n",
        "X_test_bow = count_vector.transform(X_test_raw)\n",
        "dictionary = count_vector.get_feature_names_out()\n",
        "\n",
        "print(\"Shape of preprocessed training data X using BoW model is: \", X_train_bow.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3a48rJjEHcG",
        "outputId": "29671b0a-cee6-4a0e-bc05-54348d303d64"
      },
      "outputs": [],
      "source": [
        "# Scikit TF-IDF:\n",
        "# Documentation: (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer)\n",
        "\n",
        "tfidf_vector = TfidfVectorizer(stop_words=stopword_list, ngram_range=(1, 2))\n",
        "tfidf_vector.fit(X_train_raw, X_test_raw)\n",
        "X_train_tfidf = tfidf_vector.transform(X_train_raw)\n",
        "X_test_tfidf = tfidf_vector.transform(X_test_raw)\n",
        "\n",
        "print(\"Shape of preprocessed training data X using BoW/TF-IDF model is: \", X_train_tfidf.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyttkaIPIuTR"
      },
      "source": [
        "Cast output list to ndarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSQpqMqlI0Z9",
        "outputId": "efbcea7b-dd4c-4c1a-fc0d-308dd6a2603b"
      },
      "outputs": [],
      "source": [
        "y_train = np.asarray(y_train_raw)\n",
        "y_test = np.asarray(y_test_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ob9acTnuVLG"
      },
      "source": [
        "*Luckily we're quite done with the abbreviations!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqwxPqeLvqH8"
      },
      "source": [
        "Another way: Using Word2Vec to capture the semantics\n",
        "(Um, we'd talk about that later, ok?)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uS4maCj-vvCe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fhcc_aUTueC"
      },
      "source": [
        "## Initial exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B0kWS9bktj2"
      },
      "source": [
        "Average length of the comment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n36QobPkewe",
        "outputId": "9c647833-7410-4f04-816c-be69413b7959"
      },
      "outputs": [],
      "source": [
        "# Calculate average number of characters\n",
        "sum_of_chars = sum([len(x) for x in X_train_raw])\n",
        "mean_number_chars = sum_of_chars / len(X_train_raw)\n",
        "\n",
        "# Calculate average number of words\n",
        "sum_of_words = sum([len(x.split()) for x in X_train_raw])\n",
        "mean_number_words = sum_of_words / len(X_train_raw)\n",
        "\n",
        "# Print\n",
        "print('The mean number of characters of each line is: %d' % mean_number_chars)\n",
        "print('The mean number of words of each line is: %d' % mean_number_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAZxbqwQpJ_H"
      },
      "source": [
        "Statistic of output labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "uqs1jJTspQX5",
        "outputId": "d5cdb852-87d4-4c02-fcaa-9674d73a02e9"
      },
      "outputs": [],
      "source": [
        "# Number of labels:\n",
        "labels = np.unique(y_train)\n",
        "print('Number of labels is: %d' % len(labels))\n",
        "print('Labels: ' + ', '.join(labels))\n",
        "print('\\n----------------------------------------------------------------------------\\n')\n",
        "\n",
        "# Plot:\n",
        "df = pd.DataFrame(\n",
        "  dict(\n",
        "    labels = labels,\n",
        "    label_elements_count = [y_train_raw.count(label) for label in labels]\n",
        "  )\n",
        ")\n",
        "df = df.sort_values('label_elements_count')\n",
        "\n",
        "plt.title(label='Labels statistics')\n",
        "plt.xlabel('Labels')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.bar('labels', 'label_elements_count', data=df)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNNYNBrIts1k"
      },
      "source": [
        "Statistics of words with the highest frequency of each label:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eieb8hWmtsT1"
      },
      "outputs": [],
      "source": [
        "def show_highest_frequency_words():\n",
        "  vect_arr = X_train_bow.toarray()\n",
        "  vect_aggr = np.zeros(shape=(len(labels), vect_arr.shape[1]))\n",
        "\n",
        "  for idx in range(len(vect_arr)):\n",
        "    label_idx = int(np.where(labels==y_train[idx])[0][0])\n",
        "\n",
        "    vect_aggr[label_idx] += vect_arr[idx]\n",
        "\n",
        "  fig, axs = plt.subplots(3, 2)\n",
        "\n",
        "  for label_idx in range(len(labels)):\n",
        "    axs_x, axs_y = label_idx // 2, label_idx % 2\n",
        "\n",
        "    plt_ref = axs[axs_x][axs_y]\n",
        "    plt_ref.set_title(labels[label_idx].upper())\n",
        "\n",
        "    x_axis, y_axis = list(), list()\n",
        "    n_argmax = np.argpartition(vect_aggr[label_idx], -7)[-7:]\n",
        "    n_argmax = n_argmax[np.argsort(vect_aggr[label_idx][n_argmax])]\n",
        "    for i in n_argmax:\n",
        "      x_axis.append(dictionary[i])\n",
        "      y_axis.append(vect_aggr[label_idx][i])\n",
        "\n",
        "    x_axis = np.asarray(x_axis)\n",
        "    y_axis = np.asarray(y_axis)\n",
        "\n",
        "    plt_ref.barh(x_axis, y_axis)\n",
        "\n",
        "  # Adjust layout\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n",
        "\n",
        "show_highest_frequency_words()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Fixing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This part will eliminate all the words that have bad influence to our data.\n",
        "All the words will be stored in a file stored in file *filtered_words.txt*\n",
        "\n",
        "* Words appears so many times but don't contribute much (*feel*, *feeling*,...).\n",
        "* Words have no mean (*aa*,*ab*,...)\n",
        "* Words appears only a few"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file = open(\"data/stopwords/filtered_words.txt\", 'r')\n",
        "filtered_words = file.read().split('\\n')\n",
        "\n",
        "new_stopwords = stopword_list + filtered_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create tokenize function with the help of nltk packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in new_stopwords]\n",
        "    stems = [stemmer.stem(token) for token in tokens]\n",
        "    return stems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the data again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "count_vector = CountVectorizer(stop_words=new_stopwords, tokenizer=tokenize, ngram_range=(1, 2))\n",
        "count_vector.fit(X_train_raw, X_test_raw)\n",
        "X_train_bow = count_vector.transform(X_train_raw)\n",
        "X_test_bow = count_vector.transform(X_test_raw)\n",
        "dictionary = count_vector.get_feature_names_out()\n",
        "\n",
        "tfidf_vector = TfidfVectorizer(stop_words=new_stopwords, tokenizer=tokenize, ngram_range=(1, 2))\n",
        "tfidf_vector.fit(X_train_raw, X_test_raw)\n",
        "X_train_tfidf = tfidf_vector.transform(X_train_raw)\n",
        "X_test_tfidf = tfidf_vector.transform(X_test_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(dictionary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fixing results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_highest_frequency_words()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9syl2WgjTppC"
      },
      "source": [
        "## Variables summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvyhe6bnT0at"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**X_train_raw**, **y_train_raw**: ***list***\n",
        "\n",
        "Raw training data which is extracted directly from files.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**X_test**, **y_test**: ***list***\n",
        "\n",
        "  Raw testing data which is extracted directly from files.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**stopword_list**: ***list***\n",
        "\n",
        " List of stop words used in BoW and BoW/TF-IDF models\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**dictionary**: ***numpy.ndarray***\n",
        "\n",
        " Dictionary of words which is used to vectorized the data and number of occurences.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**X_train_bow**: ***scipy.sparse._csr.csr_matrix***\n",
        "\n",
        " Training data input which is vectorized by the BoW model.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**X_train_tfidf**: ***scipy.sparse._csr.csr_matrix***\n",
        "\n",
        " Training data input which is vectorized by the BoW/TFIDF model\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**X_test_bow**: ***scipy.sparse._csr.csr_matrix***\n",
        "\n",
        " Testing data input which is vectorized by the BoW model.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**X_test_tfidf**: ***scipy.sparse._csr.csr_matrix***\n",
        "\n",
        " Testing data input which is vectorized by the BoW/TFIDF model\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**y_train**: ***numpy.ndarray***\n",
        "\n",
        " Preprocessed traning data output\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgd9jGkTFGQF"
      },
      "source": [
        "# **Model training and result**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVjzaZurZGdl"
      },
      "source": [
        "## Preset functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9PsIEUmZPOj"
      },
      "source": [
        "Current preset functions:\n",
        "\n",
        "---\n",
        "\n",
        "model_evaluate_full(model, X_train, X_test, y_train, y_test, include_training = False): Evaluate a model fully.\n",
        "- model: Your model.\n",
        "- X_train, X_test, y_train, y_test: The datasets used to evluate the model.\n",
        "- include_training: Trigger True if you want to output the training metrics. On default, false.\n",
        "\n",
        "---\n",
        "\n",
        "draw_learning_curve(model, X_train, y_train, cv = 5, train_sizes = np.linspace(0.2, 1, 5), scoring = 'accuracy'): Draw the learning curve for a model.\n",
        "- model: Your model.\n",
        "- X_train, y_train: The datasets on which you want to draw the learning curve.\n",
        "- cv: Number of cross-validation folds you want to commit. On default, 5.\n",
        "- train_sizes: The threshold list for the learning curve to be evaluated. On default, [.2, .4, .6, .8, 1]\n",
        "- scoring: Scoring metric used. On default, accuracy score is used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep6yxzdEbMiE"
      },
      "source": [
        "model_evaluate_full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFDBd71fTbi4"
      },
      "outputs": [],
      "source": [
        "def model_evaluate_full(model, X_train, X_test, y_train, y_test, include_training = False):\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  if include_training == True:\n",
        "    y_pred = model.predict(X_train)\n",
        "    print(\"Accuracy score on the train: {:.2f}\".format(accuracy_score(y_pred, y_train)))\n",
        "    print(\"F1 score on the train: {:.2f}\".format(f1_score(y_pred, y_train, average = 'micro')))\n",
        "    cm = confusion_matrix(y_pred, y_train)\n",
        "    ConfusionMatrixDisplay(cm).plot()\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"Accuracy score on the test: {:.2f}\".format(accuracy_score(y_pred, y_test)))\n",
        "  print(\"F1 score on the test: {:.2f}\".format(f1_score(y_pred, y_test, average = 'micro')))\n",
        "  cm = confusion_matrix(y_pred, y_test)\n",
        "  ConfusionMatrixDisplay(cm).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgZV17ggbQEw"
      },
      "source": [
        "draw_learning_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvoWbvCmiVNv"
      },
      "outputs": [],
      "source": [
        "def draw_learning_curve(model, X_train, y_train, cv = 5, train_sizes = np.linspace(0.2, 1, 5), scoring = 'accuracy'):\n",
        "  _, train_score, test_score = learning_curve(model, X_train_bow, y_train, n_jobs = -1, cv = cv,\n",
        "                                              train_sizes = train_sizes, scoring = scoring)\n",
        "\n",
        "  train_mean_score = np.mean(train_score, axis = 1)\n",
        "  train_std_score = np.std(train_score, axis = 1)\n",
        "  test_mean_score = np.mean(test_score, axis = 1)\n",
        "  test_std_score = np.std(test_score, axis = 1)\n",
        "\n",
        "  plt.fill_between(train_sizes, train_mean_score - train_std_score, train_mean_score + train_std_score, alpha = 0.1, color = 'g')\n",
        "  plt.fill_between(train_sizes, test_mean_score - test_std_score, test_mean_score + test_std_score, alpha = 0.1, color = 'r')\n",
        "\n",
        "  plt.plot(train_sizes, train_mean_score, color = 'g')\n",
        "  plt.plot(train_sizes, test_mean_score, color = 'r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhK_uRQbeKiA"
      },
      "source": [
        "## K-nearest neighbors (KNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAXGNosdYKHa"
      },
      "source": [
        "**DEVELOPER'S NOTE: k-NN code will be the anchor code for implementing other models. Please refer to this code as a guide when you work on other classes of models. Please refer to SleepyHunter if you ever need any more preset functions, as well as when you find a bug. Regards.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmExxIMCRFRY"
      },
      "source": [
        "We define the model first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "7wwOqVwVSn-G",
        "outputId": "affc4d68-7dac-4f99-c3d9-26dc308651ae"
      },
      "outputs": [],
      "source": [
        "knn_model = KNeighborsClassifier(n_neighbors = 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc_r_U-hUQEi"
      },
      "source": [
        "Getting prediction on training set (without cross validation) then evaluate it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "lmjNUa3fUTRU",
        "outputId": "a8e50680-47e2-4883-c422-9b6f4e06013b"
      },
      "outputs": [],
      "source": [
        "model_evaluate_full(knn_model, X_train_bow, X_test_bow, y_train, y_test, include_training = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7BlI7R_iWF8"
      },
      "source": [
        "Learning curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "9qrG397GV7eI",
        "outputId": "187044b2-c65a-44de-e18b-d3eb6a4c8305"
      },
      "outputs": [],
      "source": [
        "draw_learning_curve(knn_model, X_train_bow, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52lKJfl7hUmQ"
      },
      "source": [
        "Actually I set k = 3 to beautify the record, I ran k >= 5 and it was terrible.\n",
        "Now we draw the plot for a range of k-neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "KoIZ99v0hToY",
        "outputId": "5dd813ba-20c5-40e4-e44d-6a3305dc912a"
      },
      "outputs": [],
      "source": [
        "# Setting the hyperparameter range\n",
        "K = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "accuracy_list = list()\n",
        "valid_accuracy_list = list()\n",
        "\n",
        "for k in K:\n",
        "  knn_model = KNeighborsClassifier(n_neighbors = k)\n",
        "  knn_model.fit(X_train_bow, y_train)\n",
        "\n",
        "  data_pred_y = knn_model.predict(X_test_bow)\n",
        "  data_valid_y = knn_model.predict(X_train_bow)\n",
        "\n",
        "  accuracy_list.append([k, accuracy_score(y_test, data_pred_y)])\n",
        "  valid_accuracy_list.append([k, accuracy_score(y_train, data_valid_y)])\n",
        "\n",
        "accuracy_list = np.asarray(accuracy_list)\n",
        "valid_accuracy_list = np.asarray(valid_accuracy_list)\n",
        "\n",
        "plt.plot(accuracy_list[:, 0], accuracy_list[:, 1], label = \"Testing accuracy\", color = 'b')\n",
        "plt.plot(valid_accuracy_list[:, 0], valid_accuracy_list[:, 1], label = \"Training accuracy\", color = 'r')\n",
        "plt.xlabel('Number of neighbors')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc8thpvXixGz"
      },
      "source": [
        "Using GridSearchCV to make a total search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_jb5T6miw5z",
        "outputId": "ef63c5ea-29a1-43f6-abe6-6c515c801a6b"
      },
      "outputs": [],
      "source": [
        "dict_param = {'n_neighbors': np.arange(1, 11)}\n",
        "best_knn_model = GridSearchCV(KNeighborsClassifier(), param_grid = dict_param, n_jobs = -1, cv = 10, scoring = 'accuracy')\n",
        "\n",
        "best_knn_model.fit(X_train_bow, y_train)\n",
        "\n",
        "print(\"Best parameters for k_NN:\", best_knn_model.best_params_)\n",
        "data_best_knn_pred_y = best_knn_model.predict(X_test_bow)\n",
        "print(\"Accuracy of that model:\", accuracy_score(data_best_knn_pred_y, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"I feels shitty today\"\n",
        "print('fun day' in dictionary)\n",
        "vect = count_vector.transform([text])\n",
        "print(vect)\n",
        "print(count_vector.inverse_transform(vect))\n",
        "\n",
        "best_knn_model.predict(vect)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-nyt-6tz2ku"
      },
      "source": [
        "I'm going to do just literally the same thing for TfIdf dataset... later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhO2ye_2eS8d"
      },
      "source": [
        "## Naive Bayes classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPH1AE2JFN4y"
      },
      "source": [
        "# **Conclusion**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
